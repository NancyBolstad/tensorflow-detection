(window.webpackJsonp=window.webpackJsonp||[]).push([[2],{52:function(e,t,s){"use strict";s.r(t),function(e){var o,r=s(1),n=s(4),i=s(61),c=s(62);(o="undefined"!=typeof reactHotLoaderGlobal?reactHotLoaderGlobal.enterModule:void 0)&&o(e);var a="undefined"!=typeof reactHotLoaderGlobal?reactHotLoaderGlobal.default.signature:function(e){return e};const l=()=>{const[e]=r.useState({width:600,height:600}),t=r.useRef(null);r.useEffect(()=>{},[t]),Object(i.a)({videoRef:t,options:{videoSize:e}});const{eyesPotions:s}=Object(c.a)({videoRef:t});return r.createElement(f,null,r.createElement(y,{ref:t,autoPlay:!0,width:e.width,height:e.height}),r.createElement(d,{eyesPotions:s}))};a(l,"useState{[videoSize]({width: 600, height: 600})}\nuseRef{videoRef}\nuseEffect{}\nuseMediaStream{}\nusePoseDetection{{eyesPotions}}",()=>[i.a,c.a]);const d=({eyesPotions:e})=>{const{left:t,right:s}=e;return r.createElement(h,null,r.createElement(u,{x:100*t.x,y:100*t.y}),r.createElement(u,{x:100*s.x,y:100*s.y}))},u=({x:e,y:t})=>r.createElement(p,{width:200,height:200},r.createElement(v,{width:100,height:100,x:e,y:t})),f=n.default.div`
  display: flex;
  align-items: center;
  justify-content: center;
  width: 100%;
  height: 100%;
`,y=n.default.video`
  visibility: hidden;
  position: absolute;
`,h=n.default.div`
  display: flex;
  align-items: center;
  justify-content: center;
  > *:nth-child(n + 2) {
    margin-left: 12px;
  }
`,g=n.default.div`
  width: ${e=>e.width}px;
  height: ${e=>e.height}px;
  border-radius: 50%;
`,p=Object(n.default)(g)`
  background-color: #fff;
  position: relative;
`,v=Object(n.default)(g)`
  background-color: #000;
  transform: translateX(${e=>-(1.5*e.x||50)}%)
    translateY(${e=>-(1.5*(100-e.y)||50)}%);
  position: absolute;
  top: 50%;
  left: 50%;
`,w=l;var E,m;t.default=w,(E="undefined"!=typeof reactHotLoaderGlobal?reactHotLoaderGlobal.default:void 0)&&(E.register(1.5,"COEFFICIENT","/Users/Nancy/Documents/tensorflow-detection/src/scripts/views/screen/EyeTracking.tsx"),E.register(l,"EyeTracking","/Users/Nancy/Documents/tensorflow-detection/src/scripts/views/screen/EyeTracking.tsx"),E.register(d,"Eyes","/Users/Nancy/Documents/tensorflow-detection/src/scripts/views/screen/EyeTracking.tsx"),E.register(u,"Eye","/Users/Nancy/Documents/tensorflow-detection/src/scripts/views/screen/EyeTracking.tsx"),E.register(f,"Wrapper","/Users/Nancy/Documents/tensorflow-detection/src/scripts/views/screen/EyeTracking.tsx"),E.register(y,"Video","/Users/Nancy/Documents/tensorflow-detection/src/scripts/views/screen/EyeTracking.tsx"),E.register(h,"EyesWrapper","/Users/Nancy/Documents/tensorflow-detection/src/scripts/views/screen/EyeTracking.tsx"),E.register(g,"StyledEye","/Users/Nancy/Documents/tensorflow-detection/src/scripts/views/screen/EyeTracking.tsx"),E.register(p,"WhiteEye","/Users/Nancy/Documents/tensorflow-detection/src/scripts/views/screen/EyeTracking.tsx"),E.register(v,"BlackEye","/Users/Nancy/Documents/tensorflow-detection/src/scripts/views/screen/EyeTracking.tsx"),E.register(w,"default","/Users/Nancy/Documents/tensorflow-detection/src/scripts/views/screen/EyeTracking.tsx")),(m="undefined"!=typeof reactHotLoaderGlobal?reactHotLoaderGlobal.leaveModule:void 0)&&m(e)}.call(this,s(3)(e))},53:function(e,t){},54:function(e,t){},55:function(e,t){},56:function(e,t){},57:function(e,t){},58:function(e,t){},61:function(e,t,s){"use strict";(function(e){var o,r=s(1);(o="undefined"!=typeof reactHotLoaderGlobal?reactHotLoaderGlobal.enterModule:void 0)&&o(e);var n="undefined"!=typeof reactHotLoaderGlobal?reactHotLoaderGlobal.default.signature:function(e){return e};const i="This browser does not support video capture, or this device does not have a camera",c={audio:!1,video:{facingMode:"user"}},a={videoConstraints:c,videoSize:{width:500,height:500}},l=e=>{const{videoRef:t}=e,[s,o]=r.useState(null),n={...a,...e.options};r.useEffect(()=>{if(s&&s.getTracks().forEach(e=>e.stop()),!navigator.mediaDevices)throw new Error(i);c()},[]),r.useEffect(()=>{const e=t.current;e&&(e.srcObject=s)},[s]);const c=r.useCallback(async()=>{const e=await navigator.mediaDevices.getUserMedia(n.videoConstraints).catch(e=>{throw new Error(e)});o(e)},[n.videoConstraints]);return{}};n(l,"useState{[stream, setStream](null)}\nuseEffect{}\nuseEffect{}\nuseCallback{watchMediaStream}");const d=l;var u,f;t.a=d,(u="undefined"!=typeof reactHotLoaderGlobal?reactHotLoaderGlobal.default:void 0)&&(u.register(i,"HAS_NOT_MEDIADEVICES_ERROR","/Users/Nancy/Documents/tensorflow-detection/src/scripts/hooks/useMediaStream.ts"),u.register(c,"DEFAULT_CONSTRAINTS","/Users/Nancy/Documents/tensorflow-detection/src/scripts/hooks/useMediaStream.ts"),u.register(a,"DEFAULT_OPTION","/Users/Nancy/Documents/tensorflow-detection/src/scripts/hooks/useMediaStream.ts"),u.register(l,"useMediaStream","/Users/Nancy/Documents/tensorflow-detection/src/scripts/hooks/useMediaStream.ts"),u.register(d,"default","/Users/Nancy/Documents/tensorflow-detection/src/scripts/hooks/useMediaStream.ts")),(f="undefined"!=typeof reactHotLoaderGlobal?reactHotLoaderGlobal.leaveModule:void 0)&&f(e)}).call(this,s(3)(e))},62:function(e,t,s){"use strict";(function(e){var o,r=s(1),n=(s(2),s(59));(o="undefined"!=typeof reactHotLoaderGlobal?reactHotLoaderGlobal.enterModule:void 0)&&o(e);var i="undefined"!=typeof reactHotLoaderGlobal?reactHotLoaderGlobal.default.signature:function(e){return e};const c={imageScaleFactor:.2,flipHorizontal:!1,outputStride:16},a={x:0,y:0},l={left:a,right:a},d=({videoRef:e,options:t=c})=>{const[s,o]=r.useState(null),[i,a]=r.useState(l);r.useEffect(()=>{d()},[]),r.useEffect(()=>{s&&e.current&&u(s,e.current)},[s]);const d=r.useCallback(async()=>{o(await n.a())},[]),u=r.useCallback(async(e,s)=>{const o=await e.estimateSinglePose(s,...Object.values(t)),r={width:s.videoWidth,height:s.videoHeight},[n,i]=h(o.keypoints).map(y).map(e=>f(e,r));a({left:n,right:i}),requestAnimationFrame(()=>u(e,s))},[]),f=r.useCallback((e,t)=>{const{x:s,y:o}=e,{width:r,height:n}=t;return{x:s/r,y:o/n}},[]),y=e=>e.position,h=e=>e.filter(e=>e.part.match(/Eye/));return{eyesPotions:i}};i(d,"useState{[net, setNet](null)}\nuseState{[eyesPotions, setEyesPotions](DEFAULT_EYES_POSITION)}\nuseEffect{}\nuseEffect{}\nuseCallback{loadNet}\nuseCallback{detectPoseInRealTime}\nuseCallback{getRatioToVideoSize}");const u=d;var f,y;t.a=u,(f="undefined"!=typeof reactHotLoaderGlobal?reactHotLoaderGlobal.default:void 0)&&(f.register(c,"DEFALT_OPTIONS","/Users/Nancy/Documents/tensorflow-detection/src/scripts/hooks/usePoseDetection.ts"),f.register(a,"DEFAULT_EYE_POSITION","/Users/Nancy/Documents/tensorflow-detection/src/scripts/hooks/usePoseDetection.ts"),f.register(l,"DEFAULT_EYES_POSITION","/Users/Nancy/Documents/tensorflow-detection/src/scripts/hooks/usePoseDetection.ts"),f.register(d,"usePoseDetection","/Users/Nancy/Documents/tensorflow-detection/src/scripts/hooks/usePoseDetection.ts"),f.register(u,"default","/Users/Nancy/Documents/tensorflow-detection/src/scripts/hooks/usePoseDetection.ts")),(y="undefined"!=typeof reactHotLoaderGlobal?reactHotLoaderGlobal.leaveModule:void 0)&&y(e)}).call(this,s(3)(e))}}]);